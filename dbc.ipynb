{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from struct import unpack, pack, calcsize\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DBC_FMT = {\n",
    "    'DungeonMap.dbc': 'NIIffffI',\n",
    "    'DungeonMapChunk.dbc': 'NIIIf',\n",
    "    'Spell.dbc': '234_936',\n",
    "    '234_936': \"NIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIfIIIIiiiiiiiiIIIIIIIIiiiIIIiiifffiiiIIIIIIIIIIIIIIIIIIfffIIIIIIiiiiiiIIIfffIIIIIIIIIIIIIISSSSSSSSSSSSSSSSISSSSSSSSSSSSSSSSISSSSSSSSSSSSSSSSISSSSSSSSSSSSSSSSIIIIIIIIIIIIIfffIIIIIiIIIIfffII\",\n",
    "    'SkillLine.dbc': '56_224',\n",
    "    '56_224': \"NIISSSSSSSSSSSSSSSSISSSSSSSSSSSSSSSSIISSSSSSSSSSSSSSSSII\",\n",
    "    'SkillLineAbility.dbc': 'NIIIIIIIIIIIII',\n",
    "    'SkillRaceClassInfo.dbc': 'NIIIIIII',\n",
    "    'MapDifficulty.dbc': 'NIISSSSSSSSSSSSSSSSIIIS',\n",
    "    'VideoHardware.dbc': 'NIIIIIIIIIIIIIIIIISSIII',\n",
    "    'DungeonEncounter.dbc': 'NIIIISSSSSSSSSSSSSSSSII',\n",
    "    'Exhaustion.dbc': 'NIfffSSSSSSSSSSSSSSSSII',\n",
    "    '23_92': \"NIIIIIIIIIIIIIIIIIIIIII\",\n",
    "    'WorldMapArea.dbc': \"NIISffffiiI\",\n",
    "    'WorldMapTransforms.dbc': \"NIffffIffI\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DBCHeader:\n",
    "    HEADER_FORMAT = '4sIIII'\n",
    "    HEADER_SIZE = 20\n",
    "\n",
    "    def __init__(self, iterable=(), **kwargs):\n",
    "        self.magic = b'WDBC'\n",
    "        self.record_count = 0\n",
    "        self.field_count = 0\n",
    "        self.record_size = 0\n",
    "        self.string_block_size = 1\n",
    "\n",
    "        self.__dict__.update(iterable, **kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        msg = f'magic:{self.magic}, record_count:{self.record_count}, field_count:{self.field_count}, ' \\\n",
    "              f'record_size:{self.record_size}, string_block_size:{self.string_block_size} ' \\\n",
    "              f'file_size:{DBCHeader.HEADER_SIZE + self.record_count * self.record_size + self.string_block_size}'\n",
    "        return msg\n",
    "\n",
    "    def unpack_binary(self, data):\n",
    "        [self.magic, self.record_count, self.field_count, self.record_size,\n",
    "         self.string_block_size] = unpack(self.HEADER_FORMAT, data[:self.HEADER_SIZE])\n",
    "\n",
    "    def pack_header(self):\n",
    "        # little endian\n",
    "        return pack(self.HEADER_FORMAT, self.magic, self.record_count, self.field_count, self.record_size,\n",
    "                    self.string_block_size)\n",
    "\n",
    "\n",
    "class DBC:\n",
    "    def __init__(self, iterable=(), **kwargs):\n",
    "        self.path = ''\n",
    "        self.fmt = ''\n",
    "        self.field_index = 0\n",
    "        self.header = DBCHeader()\n",
    "        self.records = {}\n",
    "        self.string_block = b'\\0'\n",
    "\n",
    "        self.__dict__.update(iterable, **kwargs)\n",
    "\n",
    "    def load(self, dbc_path, fmt='', raw_float=False):\n",
    "        with open(dbc_path, 'rb') as f:\n",
    "            data = f.read()\n",
    "\n",
    "        if len(data) == 0:\n",
    "            return\n",
    "\n",
    "        self.path = dbc_path\n",
    "\n",
    "        # Read Headers\n",
    "        self.header = DBCHeader()\n",
    "        self.header.unpack_binary(data)\n",
    "\n",
    "        k = f'{self.header.field_count}_{self.header.record_size}'\n",
    "        f_name = os.path.basename(dbc_path)\n",
    "        if not fmt:\n",
    "            if f_name in DBC_FMT and DBC_FMT[f_name] != k:\n",
    "                fmt = DBC_FMT[f_name]\n",
    "            elif k in DBC_FMT:\n",
    "                fmt = DBC_FMT[k]\n",
    "        if fmt:\n",
    "            if raw_float:\n",
    "                fmt = fmt.replace('f', 'I')\n",
    "                fmt = fmt.replace('d', 'Q')\n",
    "            self.fmt = fmt\n",
    "            fmt = fmt.replace('S', 'I')\n",
    "            fmt = fmt.replace('N', 'I')\n",
    "            assert calcsize(fmt) == self.header.record_size\n",
    "            assert len(self.fmt) == self.header.field_count\n",
    "\n",
    "        # Read Records\n",
    "        self.records = {}\n",
    "        for i in range(self.header.record_count):\n",
    "            begin = DBCHeader.HEADER_SIZE + i * self.header.record_size\n",
    "            end = begin + self.header.record_size\n",
    "            if fmt:\n",
    "                rec = unpack(fmt, data[begin:end])\n",
    "            else:\n",
    "                rec = data[begin:end]\n",
    "            self.records[rec[self.field_index]] = list(rec)\n",
    "\n",
    "        # Read String Block\n",
    "        self.string_block = data[DBCHeader.HEADER_SIZE + self.header.record_count * self.header.record_size:]\n",
    "        assert (len(self.string_block) == self.header.string_block_size)\n",
    "\n",
    "        if (not fmt) or (not self.string_block):\n",
    "            return\n",
    "\n",
    "        # preprocess String Block\n",
    "        string_map = {}\n",
    "        cnt = 0\n",
    "        for s in self.string_block.split(b'\\0'):\n",
    "            string_map[cnt] = s\n",
    "            cnt = cnt + len(s) + 1\n",
    "\n",
    "        for i in range(self.header.field_count):\n",
    "            if self.fmt[i] == 'S':\n",
    "                for rec in self.records.values():\n",
    "                    if rec[i]:\n",
    "                        rec[i] = string_map[rec[i]].decode()\n",
    "                    else:\n",
    "                        rec[i] = ''\n",
    "\n",
    "    def store(self, dbc_path):\n",
    "        if self.fmt:\n",
    "            # Generate String Block\n",
    "            field_count = len(self.fmt)\n",
    "            string_set = set()\n",
    "            for i in range(field_count):\n",
    "                if self.fmt[i] == 'S':\n",
    "                    for rec in self.records.values():\n",
    "                        if rec[i]:\n",
    "                            string_set.add(rec[i])\n",
    "\n",
    "            string_list = []\n",
    "            string_map = {b'\\0': 0}\n",
    "            cnt = 1\n",
    "            for s in string_set:\n",
    "                string_map[s] = cnt\n",
    "                b = s.encode()\n",
    "                string_list.append(b)\n",
    "                cnt += len(b) + 1\n",
    "            self.string_block = b'\\0' + b'\\0'.join(string_list) + b'\\0'\n",
    "\n",
    "            records = []\n",
    "            for r in self.records.values():\n",
    "                rec = r.copy()\n",
    "                for i in range(field_count):\n",
    "                    if self.fmt[i] == 'S':\n",
    "                        if rec[i]:\n",
    "                            rec[i] = string_map[rec[i]]\n",
    "                        else:\n",
    "                            rec[i] = 0\n",
    "                records.append(rec)\n",
    "            records.sort()\n",
    "\n",
    "            # pack records\n",
    "            fmt = self.fmt.replace('S', 'I')\n",
    "            fmt = fmt.replace('N', 'I')\n",
    "            raw_record_list = []\n",
    "            for rec in records:\n",
    "                raw_record_list.append(pack(fmt, *rec))\n",
    "\n",
    "            # Generate header\n",
    "            self.header = DBCHeader(\n",
    "                record_count=len(records),\n",
    "                field_count=len(fmt),\n",
    "                record_size=calcsize(fmt),\n",
    "                string_block_size=len(self.string_block)\n",
    "            )\n",
    "        else:\n",
    "            raw_record_list = list(self.records.values())\n",
    "        raw_records = b''.join(raw_record_list)\n",
    "        self.header.record_count = len(self.records)\n",
    "\n",
    "        with open(dbc_path, 'wb') as f:\n",
    "            f.write(self.header.pack_header())\n",
    "            f.write(raw_records)\n",
    "            f.write(self.string_block)\n",
    "\n",
    "    def import_csv(self, csv_path, fmt='', raw_float=False):\n",
    "        if not fmt:\n",
    "            fmt = self.fmt\n",
    "\n",
    "        if not fmt:\n",
    "            print('unknow format')\n",
    "            return\n",
    "\n",
    "        if raw_float:\n",
    "            fmt = fmt.replace('f', 'I')\n",
    "            fmt = fmt.replace('d', 'Q')\n",
    "\n",
    "        with open(csv_path, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            field_count = len(fmt)\n",
    "            records = [row for row in spamreader]\n",
    "            if records:\n",
    "                assert len(records[0]) == field_count\n",
    "        self.records = {}\n",
    "        for row in records[1:]:\n",
    "            for i in range(field_count):\n",
    "                if fmt[i].lower() in ['i', 'b', 'h', 'l', 'q', 'n']:\n",
    "                    row[i] = int(row[i])\n",
    "                elif fmt[i] in ['f', 'e', 'd']:\n",
    "                    row[i] = float(row[i])\n",
    "                # elif fmt[i] not in ['S', 'x', 'c', 's', 'p']:\n",
    "                #     print(f'unsupported import format:{fmt[i]}')\n",
    "                #     return False\n",
    "            self.records[row[self.field_index]] = row\n",
    "        self.fmt = fmt\n",
    "        self.path = csv_path\n",
    "\n",
    "    def export_csv(self, csv_path):\n",
    "        if not self.fmt:\n",
    "            return\n",
    "        with open(csv_path, 'w', newline='') as csvfile:\n",
    "            spamwriter = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
    "            spamwriter.writerow([f'{f}' for f in range(len(self.fmt))])\n",
    "            records = list(self.records.values())\n",
    "            records.sort()\n",
    "            for rec in records:\n",
    "                spamwriter.writerow(rec)\n",
    "\n",
    "    def import_string(self, dbc_path, merge=False):\n",
    "        if not self.fmt:\n",
    "            return\n",
    "        src_dbc = DBC()\n",
    "        src_dbc.load(dbc_path, fmt=self.fmt)\n",
    "        for f in range(self.header.field_count):\n",
    "            if self.fmt[f] == 'S':\n",
    "                for i in self.records.keys():\n",
    "                    if i in src_dbc.records and ((merge and src_dbc.records[i][f]) or (not merge)):\n",
    "                        self.records[i][f] = src_dbc.records[i][f]\n",
    "\n",
    "def diff():\n",
    "    # todo: Show changes between two dbc files\n",
    "    # diff -u file1.csv file2.csv > patchfile.patch\n",
    "    pass\n",
    "\n",
    "def apply():\n",
    "    # todo: Apply a patch to a dbc file\n",
    "    # patch file1.csv patchfile.patch\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 ms ± 16.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "478 ms ± 16.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.44 s ± 84.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "806 ms ± 51.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "magic:b'WDBC', record_count:49839, field_count:234, record_size:936, string_block_size:2307035 file_size:48956359\n"
     ]
    }
   ],
   "source": [
    "dbc = DBC()\n",
    "%timeit dbc.load('dbc/Spell_cn.dbc')\n",
    "%timeit dbc.export_csv('dbc/test.csv')\n",
    "%timeit dbc.import_csv('dbc/test.csv')\n",
    "%timeit dbc.store('dbc/test.dbc')\n",
    "print(dbc.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297 ms ± 7.04 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "magic:b'WDBC', record_count:49839, field_count:234, record_size:936, string_block_size:2317797 file_size:48967121\n",
      "1.25 s ± 37.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "795 ms ± 5.44 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "magic:b'WDBC', record_count:49839, field_count:234, record_size:936, string_block_size:2307035 file_size:48956359\n"
     ]
    }
   ],
   "source": [
    "dbc = DBC()\n",
    "%timeit dbc.load('dbc/en/Spell.dbc')\n",
    "print(dbc.header)\n",
    "%timeit dbc.import_string('dbc/cn/Spell.dbc', merge=False)\n",
    "%timeit dbc.store('dbc/test.dbc')\n",
    "print(dbc.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for d in os.listdir('dbc'):\n",
    "    for f in os.listdir(os.path.join('dbc', d)):\n",
    "        if not f.endswith('.dbc'):\n",
    "            continue\n",
    "        dbc = DBC()\n",
    "        dbc.load(os.path.join('dbc', d, f))\n",
    "        dbc.export_csv(os.path.join('dbc', d, f'{f}.csv'))\n",
    "        print(d, f, dbc.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spell.dbc magic:b'WDBC', record_count:49839, field_count:234, record_size:936, string_block_size:6473160 file_size:53122484\n"
     ]
    }
   ],
   "source": [
    "# dbc_list = ['MapDifficulty.dbc', 'SkillLine.dbc', 'Spell.dbc']\n",
    "dbc_list = ['Spell.dbc',]\n",
    "\n",
    "for d in dbc_list:\n",
    "    dbc = DBC()\n",
    "    dbc.load(os.path.join('dbc', 'en', d))\n",
    "    dbc.import_string(os.path.join('dbc', 'cn', d), merge=True)\n",
    "    # dbc.import_string(os.path.join('dbc', 'en', d), merge=True)\n",
    "    dbc.import_string(os.path.join('dbc', 'tw', d), merge=True)\n",
    "    dbc.export_csv(os.path.join('dbc', 'cn_alvin', f'{d}.csv'))\n",
    "    dbc.store(os.path.join('dbc', 'cn_alvin', d))\n",
    "    print(d, dbc.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dbc = DBC()\n",
    "dbc.load(os.path.join('dbc', 'mip_m', 'MapDifficulty.dbc'))\n",
    "dbc.import_csv(os.path.join('dbc', 'mip_m', 'MapDifficulty.dbc.csv'))\n",
    "dbc.store(os.path.join('dbc', 'mip_m', 'MapDifficulty.dbc'))\n",
    "dbc.load(os.path.join('dbc', 'mip_m', 'MapDifficulty.dbc'))\n",
    "dbc.export_csv(os.path.join('dbc', 'mip_m', 'MapDifficulty.dbc.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from zhconv import convert\n",
    "\n",
    "dbc1 = DBC()\n",
    "dbc1.load(os.path.join('dbc', 'cn', 'Spell.dbc'))\n",
    "\n",
    "dbc2 = DBC()\n",
    "dbc2.load(os.path.join('dbc', 'tw', 'Spell.dbc'))\n",
    "\n",
    "for i in dbc1.records.keys():\n",
    "    for f in range(dbc1.header.field_count):\n",
    "        if dbc1.fmt[f] == 'S':\n",
    "            s = dbc1.records[i][f]\n",
    "            if s and len(s.encode()) == len(s):\n",
    "                s2 = dbc2.records[i][f+1]\n",
    "                if s2 and len(s2.encode()) != len(s2):\n",
    "                    s2 = convert(s2, 'zh-cn')\n",
    "                    dbc1.records[i][f] = s2\n",
    "                    print(s2)\n",
    "dbc1.export_csv(os.path.join('dbc', 'Spell.dbc.csv'))\n",
    "dbc1.store(os.path.join('dbc', 'Spell.dbc'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
